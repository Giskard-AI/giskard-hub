{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example\n",
    "Here is a simple example on how to interact with the Hub from Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard_hub.client import HubClient\n",
    "\n",
    "# Initialise hub client\n",
    "hub = HubClient(api_key=\"YOUR_API_KEY\", hub_url=\"http://your-hub-instance.com/_api\")\n",
    "\n",
    "# api_key and hub url can also be provided by setting env variable GSK_API_KEY and GSK_HUB_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get some object from the server (project, model & dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard_hub.data import Dataset, Model, Project\n",
    "\n",
    "project: Project = hub.projects.list()[0]\n",
    "model: Model = hub.models.list(project.id)[0]\n",
    "dataset: Dataset = hub.datasets.list(project.id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start a new evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from giskard_hub.data import EvaluationRun\n",
    "\n",
    "\n",
    "evaluation: List[EvaluationRun] = hub.evaluate(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the evaluation to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "evaluation.wait_for_completion()\n",
    "print(evaluation.is_finished())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can print the results 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Evaluation Run </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">racy-constantia</span><span style=\"font-style: italic\">                     </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric      </span>┃<span style=\"font-weight: bold\"> Result </span>┃<span style=\"font-weight: bold\"> Details                                       </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ <span style=\"font-weight: bold\">Conformity</span>  │ <span style=\"color: #800000; text-decoration-color: #800000\">40.00%</span> │ <span style=\"color: #808080; text-decoration-color: #808080\">4 passed, 6 failed, 0 errored, 0 not executed</span> │\n",
       "│ <span style=\"font-weight: bold\">Correctness</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">90.00%</span> │ <span style=\"color: #808080; text-decoration-color: #808080\">9 passed, 1 failed, 0 errored, 0 not executed</span> │\n",
       "└─────────────┴────────┴───────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                     Evaluation Run \u001b[0m\u001b[1;3;36mracy-constantia\u001b[0m\u001b[3m                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mResult\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDetails                                      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ \u001b[1mConformity\u001b[0m  │ \u001b[31m40.00%\u001b[0m │ \u001b[90m4 passed, 6 failed, 0 errored, 0 not executed\u001b[0m │\n",
       "│ \u001b[1mCorrectness\u001b[0m │ \u001b[32m90.00%\u001b[0m │ \u001b[90m9 passed, 1 failed, 0 errored, 0 not executed\u001b[0m │\n",
       "└─────────────┴────────┴───────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.print_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
